{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH02.4. **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 신경망의 각 계층에 입력되는 데이터의 분포를 표준화하여 학습을 안정화하고 가속화하는 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 종류** :\n",
    "#### $ \\hspace{0.15cm} $ ① Input Normalization\n",
    "#### $ \\hspace{0.15cm} $ ② Batch Normalization\n",
    "#### $ \\hspace{0.15cm} $ ③ Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Input Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : **입력** 데이터를 정규화하여 평균을 $ \\, 0 $ 으로 표준편차를 $ \\, 1 $ 로 조정하는 방법\n",
    "#### $ \\Rightarrow{} X = \\frac{X - \\bar{X}}{\\sigma{}_{X}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 효과** : 입력 데이터의 스케일 차이로 인해 발생할 수 있는 학습 불안정을 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Batch Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 신경망의 각 층에서 선형 변환 출력 값 $ \\, Z $ 에 대해 정규화를 수행하는 방법\n",
    "#### $ \\Rightarrow{} \\tilde{Z} = \\gamma{}^{[l]} Z^{[l]}_{\\text{norm}} + \\beta{} \\;\\; \\text{ where } \\, Z^{[l]}_{\\text{norm}} = \\frac{Z^{[l]}-\\mu{}^{[l]}}{\\sqrt{(\\sigma{}^{[l]})^{2}+\\epsilon{}}} $\n",
    "#### $ \\hspace{3.7cm} \\text{and } \\, \\mu{}^{[l]} = \\frac{1}{m} \\cdot{} \\displaystyle\\sum^{m}_{i=1} \\textbf{z}^{[l](i)} $\n",
    "#### $ \\hspace{3.7cm} \\text{and } \\, (\\sigma{}^{[l]})^{2} = \\frac{1}{m} \\cdot{} \\displaystyle\\sum^{m}_{i=1} (\\textbf{z}^{[l](i)} - \\mu{}^{[l]})^{2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 일반적으로 미니배치(mini batch) 단위에서 적용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 효과** : \n",
    "#### $ \\hspace{0.15cm} $ ① 내부 공변량 이동(internal covariate shift) 감소\n",
    "#### $ \\hspace{0.15cm} $ ② 기울기 안정화 : 손실함수의 최적화 지형(landscape)을 부드럽게 만듬\n",
    "#### $ \\hspace{0.15cm} $ ③ 과적합 방지 : $ \\mu{}^{[l]}, \\, \\sigma{}^{[l]} $ 의 사용으로 일종의 노이즈가 추가됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`) Internal Covariate Shift** : 신경망 내부에서 각 층에 입력되는 활성화 값의 분포가 학습 과정에서 지속적으로 변화하는 현상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 최근 연구에서는 batch normalization이 내부 공변량 이동을 감소하지 못하고, \n",
    "#### $ \\hspace{0.875cm} $ 내부 공변량 이동이 발생하더라도 학습에 영향을 미치지 않는다고 주장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Layer Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : **[CONTENTS]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 효과** : **[CONTENTS]**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
